{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "182f7623",
   "metadata": {},
   "source": [
    "## WEB-SCRAPPING ASSIGNMENT - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f0448f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49e4c90",
   "metadata": {},
   "source": [
    "# Q1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d678ad14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most viewed videos on YouTube from Wikipedia\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Uploaded Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>7,046,700,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>3,002,800,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>2,894,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>803,700,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baby</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>February 19, 2010</td>\n",
       "      <td>245,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bad Romance</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>November 24, 2009</td>\n",
       "      <td>178,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charlie Bit My Finger</td>\n",
       "      <td>HDCYT</td>\n",
       "      <td>May 22, 2007</td>\n",
       "      <td>128,900,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Evolution of Dance</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>118,900,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Girlfriend</td>\n",
       "      <td>RCA Records</td>\n",
       "      <td>February 27, 2007</td>\n",
       "      <td>92,600,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Evolution of Dance</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>78,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Music Is My Hot Hot Sex</td>\n",
       "      <td>CLARUSBARTEL72</td>\n",
       "      <td>April 9, 2007</td>\n",
       "      <td>76,600,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Evolution of Dance</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>10,600,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pokemon Theme Music Video</td>\n",
       "      <td>Smosh</td>\n",
       "      <td>November 28, 2005</td>\n",
       "      <td>4,300,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Myspace – The Movie</td>\n",
       "      <td>eggtea</td>\n",
       "      <td>January 31, 2006</td>\n",
       "      <td>2,700,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Phony Photo Booth</td>\n",
       "      <td>mugenized</td>\n",
       "      <td>December 1, 2005</td>\n",
       "      <td>3,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Chronic of Narnia Rap</td>\n",
       "      <td>youtubedude</td>\n",
       "      <td>December 18, 2005</td>\n",
       "      <td>2,300,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ronaldinho: Touch of Gold</td>\n",
       "      <td>Nikesoccer</td>\n",
       "      <td>October 21, 2005</td>\n",
       "      <td>255,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I/O Brush</td>\n",
       "      <td>larfus</td>\n",
       "      <td>October 5, 2005</td>\n",
       "      <td>247,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Me at the zoo</td>\n",
       "      <td>jawed</td>\n",
       "      <td>April 23, 2005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name                                       Artist  \\\n",
       "0            Baby Shark Dance  Pinkfong Baby Shark - Kids' Songs & Stories   \n",
       "1                   Despacito                                   Luis Fonsi   \n",
       "2               See You Again                                  Wiz Khalifa   \n",
       "3               Gangnam Style                                          Psy   \n",
       "4                        Baby                                Justin Bieber   \n",
       "5                 Bad Romance                                    Lady Gaga   \n",
       "6       Charlie Bit My Finger                                        HDCYT   \n",
       "7          Evolution of Dance                               Judson Laipply   \n",
       "8                  Girlfriend                                  RCA Records   \n",
       "9          Evolution of Dance                               Judson Laipply   \n",
       "10    Music Is My Hot Hot Sex                               CLARUSBARTEL72   \n",
       "11         Evolution of Dance                               Judson Laipply   \n",
       "12  Pokemon Theme Music Video                                        Smosh   \n",
       "13        Myspace – The Movie                                       eggtea   \n",
       "14          Phony Photo Booth                                    mugenized   \n",
       "15  The Chronic of Narnia Rap                                  youtubedude   \n",
       "16  Ronaldinho: Touch of Gold                                   Nikesoccer   \n",
       "17                  I/O Brush                                       larfus   \n",
       "18              Me at the zoo                                        jawed   \n",
       "\n",
       "        Uploaded Date          Views  \n",
       "0       June 17, 2016  7,046,700,000  \n",
       "1    January 12, 2017  3,002,800,000  \n",
       "2       April 6, 2015  2,894,000,000  \n",
       "3       July 15, 2012    803,700,000  \n",
       "4   February 19, 2010    245,400,000  \n",
       "5   November 24, 2009    178,400,000  \n",
       "6        May 22, 2007    128,900,000  \n",
       "7       April 6, 2006    118,900,000  \n",
       "8   February 27, 2007     92,600,000  \n",
       "9       April 6, 2006     78,400,000  \n",
       "10      April 9, 2007     76,600,000  \n",
       "11      April 6, 2006     10,600,000  \n",
       "12  November 28, 2005      4,300,000  \n",
       "13   January 31, 2006      2,700,000  \n",
       "14   December 1, 2005      3,400,000  \n",
       "15  December 18, 2005      2,300,000  \n",
       "16   October 21, 2005        255,000  \n",
       "17    October 5, 2005        247,000  \n",
       "18     April 23, 2005              1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's first connect to Webdriver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "# Opening target url page on automated chrome browser\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Creating the empty list\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload=[]\n",
    "Views=[]\n",
    "\n",
    "# Scraping Song Name\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[1]\"):\n",
    "    Name.append(i.text.split('\"')[1])\n",
    "\n",
    "# Scraping Artist name\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[2]\"):\n",
    "    Artist.append(i.text.split('[')[0])\n",
    "\n",
    "# Scraping the No of Views\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[3]\"):\n",
    "    Views.append(i.text)\n",
    "\n",
    "# Scraping the Uploaded date\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[4]\"):\n",
    "    Upload.append(i.text)\n",
    "    \n",
    "Youtube={'Name':Name,'Artist':Artist,'Uploaded Date':Upload,'Views':Views}\n",
    "df=pd.DataFrame(data=Youtube)\n",
    "print('Most viewed videos on YouTube from Wikipedia')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf58753",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc4b66",
   "metadata": {},
   "source": [
    "# Q2. Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f90614d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team India International Fixtures\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASIA CUP WOMENS 2022</td>\n",
       "      <td>India Women vs Bangladesh Women</td>\n",
       "      <td>Sylhet International Cricket Stadium,</td>\n",
       "      <td>8 OCT 2022</td>\n",
       "      <td>1:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>India vs South Africa</td>\n",
       "      <td>JSCA International Stadium Complex,</td>\n",
       "      <td>9 OCT 2022</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASIA CUP WOMENS 2022</td>\n",
       "      <td>India Women vs Thailand Women</td>\n",
       "      <td>Sylhet International Cricket Stadium,</td>\n",
       "      <td>10 OCT 2022</td>\n",
       "      <td>1:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>India vs South Africa</td>\n",
       "      <td>Arun Jaitley Stadium,</td>\n",
       "      <td>11 OCT 2022</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2022</td>\n",
       "      <td>India vs Pakistan</td>\n",
       "      <td>Melbourne Cricket Ground,</td>\n",
       "      <td>23 OCT 2022</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2022</td>\n",
       "      <td>India vs TBD</td>\n",
       "      <td>Sydney Cricket Ground,</td>\n",
       "      <td>27 OCT 2022</td>\n",
       "      <td>12:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2022</td>\n",
       "      <td>India vs South Africa</td>\n",
       "      <td>WACA Ground,</td>\n",
       "      <td>30 OCT 2022</td>\n",
       "      <td>4:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2022</td>\n",
       "      <td>India vs Bangladesh</td>\n",
       "      <td>Adelaide Oval,</td>\n",
       "      <td>2 NOV 2022</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Title  \\\n",
       "0                           ASIA CUP WOMENS 2022   \n",
       "1  SOUTH AFRICA TOUR OF INDIA ODI SERIES 2022-23   \n",
       "2                           ASIA CUP WOMENS 2022   \n",
       "3  SOUTH AFRICA TOUR OF INDIA ODI SERIES 2022-23   \n",
       "4                    ICC MENS T20 WORLD CUP 2022   \n",
       "5                    ICC MENS T20 WORLD CUP 2022   \n",
       "6                    ICC MENS T20 WORLD CUP 2022   \n",
       "7                    ICC MENS T20 WORLD CUP 2022   \n",
       "\n",
       "                            Series                                  Place  \\\n",
       "0  India Women vs Bangladesh Women  Sylhet International Cricket Stadium,   \n",
       "1            India vs South Africa    JSCA International Stadium Complex,   \n",
       "2    India Women vs Thailand Women  Sylhet International Cricket Stadium,   \n",
       "3            India vs South Africa                  Arun Jaitley Stadium,   \n",
       "4                India vs Pakistan              Melbourne Cricket Ground,   \n",
       "5                     India vs TBD                 Sydney Cricket Ground,   \n",
       "6            India vs South Africa                           WACA Ground,   \n",
       "7              India vs Bangladesh                         Adelaide Oval,   \n",
       "\n",
       "          Date          Time  \n",
       "0   8 OCT 2022   1:00 PM IST  \n",
       "1   9 OCT 2022   1:30 PM IST  \n",
       "2  10 OCT 2022   1:00 PM IST  \n",
       "3  11 OCT 2022   1:30 PM IST  \n",
       "4  23 OCT 2022   1:30 PM IST  \n",
       "5  27 OCT 2022  12:30 PM IST  \n",
       "6  30 OCT 2022   4:30 PM IST  \n",
       "7   2 NOV 2022   1:30 PM IST  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's first connect to webdriver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "# Opening target url page on automated chrome browser\n",
    "driver.get(\"https://www.bcci.tv\")\n",
    "driver.maximize_window()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Clicking on International tab\n",
    "driver.find_element(By.XPATH,'//*[@id=\"navigation\"]/ul[1]/li[2]/a').click()\n",
    "\n",
    "time.sleep(1)\n",
    "# Creating the empty list\n",
    "Title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "\n",
    "# Scraping the Title Name\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]'):\n",
    "    Title.append(i.text)\n",
    "\n",
    "# Scraping the series name\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"fixture-card-mid d-flex align-items-center justify-content-between\"]'):\n",
    "    Series.append(i.text.replace('\\n',' '))\n",
    "\n",
    "# Scraping the place\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]'):\n",
    "    Place.append(i.text)\n",
    "    \n",
    "# Scraping the date\n",
    "for i in driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]'):\n",
    "    Date.append(i.text)\n",
    "\n",
    "# Scraping the time\n",
    "for i in driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]'):\n",
    "    Time.append(i.text)\n",
    "    \n",
    "# Creating the DataFrame\n",
    "bcci={'Title':Title,'Series':Series,'Place':Place,'Date':Date,'Time':Time}\n",
    "df=pd.DataFrame(data=bcci)\n",
    "print('Team India International Fixtures')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b76857",
   "metadata": {},
   "source": [
    "# Q4. Scrape the details of State-wise GDP of India from statisticstime.com.      Url = http://statisticstimes.com\n",
    "\n",
    "You have to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP(18-19)\n",
    "\n",
    "D) GSDP(17-18)\n",
    "\n",
    "E) Share(2017)\n",
    "\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa813ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first connect to webdriver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "# Opening target url page on automated chrome browser\n",
    "driver.get(\"http://statisticstimes.com/\")\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d23847a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State-wise GDP of India from www.statisticstime.com\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP 19-20</th>\n",
       "      <th>GSDP 18-19</th>\n",
       "      <th>Share 18-19</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP 19-20 GSDP 18-19 Share 18-19      GDP\n",
       "0     1                Maharashtra          -  2,632,792      13.94%  399.921\n",
       "1     2                 Tamil Nadu  1,845,853  1,630,208       8.63%  247.629\n",
       "2     3              Uttar Pradesh  1,687,818  1,584,764       8.39%  240.726\n",
       "3     4                    Gujarat          -  1,502,899       7.96%  228.290\n",
       "4     5                  Karnataka  1,631,977  1,493,127       7.91%  226.806\n",
       "5     6                West Bengal  1,253,832  1,089,898       5.77%  165.556\n",
       "6     7                  Rajasthan  1,020,989    942,586       4.99%  143.179\n",
       "7     8             Andhra Pradesh    972,782    862,957       4.57%  131.083\n",
       "8     9                  Telangana    969,604    861,031       4.56%  130.791\n",
       "9    10             Madhya Pradesh    906,672    809,592       4.29%  122.977\n",
       "10   11                     Kerala          -    781,653       4.14%  118.733\n",
       "11   12                      Delhi    856,112    774,870       4.10%  117.703\n",
       "12   13                    Haryana    831,610    734,163       3.89%  111.519\n",
       "13   14                      Bihar    611,804    530,363       2.81%   80.562\n",
       "14   15                     Punjab    574,760    526,376       2.79%   79.957\n",
       "15   16                     Odisha    521,275    487,805       2.58%   74.098\n",
       "16   17                      Assam          -    315,881       1.67%   47.982\n",
       "17   18               Chhattisgarh    329,180    304,063       1.61%   46.187\n",
       "18   19                  Jharkhand    328,598    297,204       1.57%   45.145\n",
       "19   20                Uttarakhand          -    245,895       1.30%   37.351\n",
       "20   21            Jammu & Kashmir          -    155,956       0.83%   23.690\n",
       "21   22           Himachal Pradesh    165,472    153,845       0.81%   23.369\n",
       "22   23                        Goa     80,449     73,170       0.39%   11.115\n",
       "23   24                    Tripura     55,984     49,845       0.26%    7.571\n",
       "24   25                 Chandigarh          -     42,114       0.22%    6.397\n",
       "25   26                 Puducherry     38,253     34,433       0.18%    5.230\n",
       "26   27                  Meghalaya     36,572     33,481       0.18%    5.086\n",
       "27   28                     Sikkim     32,496     28,723       0.15%    4.363\n",
       "28   29                    Manipur     31,790     27,870       0.15%    4.233\n",
       "29   30                   Nagaland          -     27,283       0.14%    4.144\n",
       "30   31          Arunachal Pradesh          -     24,603       0.13%    3.737\n",
       "31   32                    Mizoram     26,503     22,287       0.12%    3.385\n",
       "32   33  Andaman & Nicobar Islands          -          -           -        -"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting to the Indian page under economy tab\n",
    "page=driver.find_element(By.XPATH,\"//div[@class='dropdown-content']/a[3]\")\n",
    "driver.get(page.get_attribute('href'))\n",
    "\n",
    "#clicking on GDP of indian states\n",
    "driver.find_element(By.XPATH,\"//ul[@style='list-style-type:none;margin-left:20px;']/li[1]/a\").click()\n",
    "\n",
    "# Creating the empty list\n",
    "Rank=[]\n",
    "state=[]\n",
    "GSDP1=[]\n",
    "GSDP2=[]\n",
    "share=[]\n",
    "GDP=[]\n",
    "\n",
    "# Scraping for name\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[1]\"):\n",
    "    Rank.append(i.text)\n",
    "\n",
    "# Scraping for state name\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[2]\"):\n",
    "    state.append(i.text)\n",
    "\n",
    "# Scraping for GSDP1\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[3]\"):\n",
    "    GSDP1.append(i.text)\n",
    "\n",
    "# Scraping for GSDP1\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[4]\"):\n",
    "    GSDP2.append(i.text)\n",
    "    \n",
    "# Scraping for share\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[5]\"):\n",
    "    share.append(i.text)\n",
    "    \n",
    "# Scraping for GDP\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[6]\"):\n",
    "    GDP.append(i.text)\n",
    "    \n",
    "time.sleep(1)\n",
    "\n",
    "# Creating the DataFrame\n",
    "gdp_State={'Rank':Rank,'State':state,'GSDP 19-20':GSDP1,'GSDP 18-19':GSDP2,'Share 18-19':share,'GDP':GDP}\n",
    "df=pd.DataFrame(data=gdp_State)\n",
    "print('State-wise GDP of India from www.statisticstime.com')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f48356c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcb701e",
   "metadata": {},
   "source": [
    "# Q7. Scrape the details of Data science recruiters from naukri.com.                 \n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Designation\n",
    "\n",
    "C) Company\n",
    "\n",
    "D) Skills they hire for\n",
    "\n",
    "E) Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5064cbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Science recruiters from Naukri\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>UK - (london)</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Trivandrum</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Indore</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Social Media, digital media maketing, seo, smm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Priyanka Akiri</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Infinitive Software Solutions</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Oracle Dba, Data Science, Data Warehousing, ET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Qa, Ui/ux, Java Developer, Java Architect, C++...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Business Intelligence, Data Warehousing, Data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Office Administration, Hr Administration, tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Vaishnavi Kudalkar</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Codeachive learning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Data Science, Python, Data Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Bhopal</td>\n",
       "      <td>Big Data, Hadoop, Data Analytics, Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sakshi Chhikara</td>\n",
       "      <td>Assistant Manager HR</td>\n",
       "      <td>BIZ INFOTECNO PRIVATE LIMITED</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>React.js, Data Science, Java, Front End, Busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Bristlecone India Ltd</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Qlikview, Qlik Sense, Microsoft Azure, Power B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Navi Mumbai</td>\n",
       "      <td>Telecalling, Client Interaction, Marketing, Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Novelworx Digital Solutions</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Corporate Sales, Software Development, Softwar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Data Analytics, Data Science, Machine Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Machine Learning, Python, R, Dee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Big Data, Data Science, Artificial Intelligenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "      <td>Exela Technologies</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Java, Net, Angularjs, Hr, Infrastructure, Mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Autumn Leaf Consulting Services Private...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Software Architecture, Vp Engineering, Product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Data Science, Hadoop, Rpas, Devops, Python, Aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>-</td>\n",
       "      <td>Signal Processing, Machine Learning, Neural Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>R.S Consultancy &amp;amp; Services</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Web Technologies, Project Management, Software...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Server Administartion, Verilog, Vhdl, Digital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Mysoru / Mysore</td>\n",
       "      <td>Data Analytics, Managed Services, Team Leading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Avodha</td>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>Nikitha Palaparthi</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Ethical Hacking, Security Operations Center, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Data Science, Machine Learning, Big Data Analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Independent Consultant</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Data Science, Artificial Intelligence, analyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Machine Learning, Artificial Intelligence, Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>C, C++, Artificial Intelligence, Python, Php, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>3D India Staffing Research &amp;amp; Consulting...</td>\n",
       "      <td>Aligarh</td>\n",
       "      <td>Relationship Management, Retail Sales, Private...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>O.C. Tanner</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Data Science, Software Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Demand Matrix</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Big Data Analytics, Digital Mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Data Science, Recruitment, Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head Analytics</td>\n",
       "      <td>Suntech Global</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>B.Tech, Tableau, Statistics, R, Analytics, Tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Indore</td>\n",
       "      <td>Software Development, Business Intelligence, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Data Science, Node.js, Angularjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director Global Delivery</td>\n",
       "      <td>MRP Advisers</td>\n",
       "      <td>MYSORE</td>\n",
       "      <td>Data Science, Media Marketing, Resource Planni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co Founder</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Data Analysis, Learning, Data Science, Compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Java, Hadoop, R, Machine Learning, Spark, Flum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Software Development, Core Java, Unit Testing,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>Granular.ai</td>\n",
       "      <td>-</td>\n",
       "      <td>Machine Learning, Data Science, Product Manage...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "0                                    Aakash Harit   \n",
       "1                            shravan Kumar Gaddam   \n",
       "2                        MARSIAN Technologies LLP   \n",
       "3                                    Anik Agrawal   \n",
       "4                                    subhas patel   \n",
       "5    Abhishek - Only Analytics Hiring - India and   \n",
       "6   Institute for Financial Management and Resear   \n",
       "7                                     Balu Ramesh   \n",
       "8                                   Asif Lucknowi   \n",
       "9                                 InstaFinancials   \n",
       "10                             Mahesh Babu Channa   \n",
       "11                                 Priyanka Akiri   \n",
       "12                                Kalpana Dumpala   \n",
       "13                                        Mubarak   \n",
       "14                                 Kushal Rastogi   \n",
       "15                             Vaishnavi Kudalkar   \n",
       "16                                   Kapil Devang   \n",
       "17                                Sakshi Chhikara   \n",
       "18                                    Ruchi Dhote   \n",
       "19                                  Manisha Yadav   \n",
       "20                                    Riya Rajesh   \n",
       "21                           Rashmi Bhattacharjee   \n",
       "22                                  Faizan Kareem   \n",
       "23                                 Rithika dadwal   \n",
       "24                             Sandhya Khandagale   \n",
       "25                                      Shaun Rao   \n",
       "26                                  Azahar Shaikh   \n",
       "27                                          Manas   \n",
       "28                                          kumar   \n",
       "29                                   Sunil Vedula   \n",
       "30                                    Rajat Kumar   \n",
       "31                                Dhruv Dev Dubey   \n",
       "32                                      Jayanth N   \n",
       "33                                         Avodha   \n",
       "34                                       SREEDHAR   \n",
       "35                                    Priya Khare   \n",
       "36                                    Amit Sharma   \n",
       "37                                          Kanan   \n",
       "38                           Shashikant Chaudhary   \n",
       "39                                           Brad   \n",
       "40                                   Rutuja Pawar   \n",
       "41                            Madhusudhan Sridhar   \n",
       "42                                    Ankit Sinha   \n",
       "43                                 Gaurav Chouhan   \n",
       "44                                   Rashi Kacker   \n",
       "45                                        Ashwini   \n",
       "46                                   Balaji Kolli   \n",
       "47                                 Rajani Nagaraj   \n",
       "48                                    ROHIT Kumar   \n",
       "49                                 Amir Chowdhury   \n",
       "\n",
       "                            Designation  \\\n",
       "0                            HR Manager   \n",
       "1                     Company Recruiter   \n",
       "2                            Company HR   \n",
       "3                     Company Recruiter   \n",
       "4                           Founder CEO   \n",
       "5           Recruitment Lead Consultant   \n",
       "6                     Programme Manager   \n",
       "7                      HR Administrator   \n",
       "8                              Director   \n",
       "9                        Human Resource   \n",
       "10                         HR Team Lead   \n",
       "11                           HR Manager   \n",
       "12                     Executive Hiring   \n",
       "13                           Company HR   \n",
       "14                           Company HR   \n",
       "15                         HR Executive   \n",
       "16                           HR Manager   \n",
       "17                 Assistant Manager HR   \n",
       "18  Senior Executive Talent Acquisition   \n",
       "19                         HR Executive   \n",
       "20           Manager Talent Acquisition   \n",
       "21                              HR Head   \n",
       "22                           HR MANAGER   \n",
       "23                         HR Recruiter   \n",
       "24                         HR Recruiter   \n",
       "25              Manager Human Resources   \n",
       "26                    Company Recruiter   \n",
       "27              Lead Talent acquisition   \n",
       "28                           Proprietor   \n",
       "29                                  CEO   \n",
       "30                          Founder CEO   \n",
       "31             Company Recruitment Head   \n",
       "32                      Project Manager   \n",
       "33       Business Development Associate   \n",
       "34               Recruitment Consultant   \n",
       "35                       Senior Manager   \n",
       "36                           Consultant   \n",
       "37         senior technology instructor   \n",
       "38             HR Recruiter/HR Excutive   \n",
       "39        Manager, Technical Recruiting   \n",
       "40                  Technical Recruiter   \n",
       "41                      Erp Implementer   \n",
       "42                       Head Analytics   \n",
       "43              Chief Technical Officer   \n",
       "44                   Sr Product Manager   \n",
       "45             Director Global Delivery   \n",
       "46                           Co Founder   \n",
       "47                           HR Manager   \n",
       "48                            Architect   \n",
       "49                     Managing Partner   \n",
       "\n",
       "                                           Company                  Location  \\\n",
       "0                             Data Science Network                     Delhi   \n",
       "1                    Shore Infotech India Pvt. Ltd  Hyderabad / Secunderabad   \n",
       "2                         MARSIAN Technologies LLP                      Pune   \n",
       "3            Enerlytics Software Solutions Pvt Ltd                 Ahmedabad   \n",
       "4                                  LibraryXProject             UK - (london)   \n",
       "5       Apidel Technologies Division of Transpower         Vadodara / Baroda   \n",
       "6                                             IFMR                   Chennai   \n",
       "7                      Techvantage Systems Pvt Ltd                Trivandrum   \n",
       "8                       Weupskill- Live Wire India                    Indore   \n",
       "9                 CBL Data Science Private Limited     Bengaluru / Bangalore   \n",
       "10                               SocialPrachar.com  Hyderabad / Secunderabad   \n",
       "11                   Infinitive Software Solutions                 Hyderabad   \n",
       "12                              Innominds Software  Hyderabad / Secunderabad   \n",
       "13                                        MoneyTap     Bengaluru / Bangalore   \n",
       "14              QuantMagnum Technologies Pvt. Ltd.                    Mumbai   \n",
       "15                             Codeachive learning                    Mumbai   \n",
       "16                                  BISP Solutions                    Bhopal   \n",
       "17                   BIZ INFOTECNO PRIVATE LIMITED                Chandigarh   \n",
       "18                           Bristlecone India Ltd                      Pune   \n",
       "19                                        Easi Tax               Navi Mumbai   \n",
       "20                     Novelworx Digital Solutions                    Cochin   \n",
       "21         AXESTRACK SOFTWARE SOLUTIONS PRIVATE...                     Delhi   \n",
       "22                   FirstTech Consaltants Pvt.Ltd  Hyderabad / Secunderabad   \n",
       "23                                Affine Analytics                      Pune   \n",
       "24                 Compumatrice Multimedia Pvt Ltd                      Pune   \n",
       "25                              Exela Technologies                      Pune   \n",
       "26                 NEAL ANALYTICS SERVICES PVT LTD                      Pune   \n",
       "27      Autumn Leaf Consulting Services Private...     Bengaluru / Bangalore   \n",
       "28                                         trainin     Bengaluru / Bangalore   \n",
       "29                            Nanoprecise Sci Corp                         -   \n",
       "30                  R.S Consultancy &amp; Services                     Delhi   \n",
       "31                                    Confidential     Bengaluru / Bangalore   \n",
       "32        Dollarbird Information Services Pvt, Ltd           Mysoru / Mysore   \n",
       "33                              Nikitha Palaparthi  Hyderabad / Secunderabad   \n",
       "34     JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED  Hyderabad / Secunderabad   \n",
       "35                          Independent Consultant     Bengaluru / Bangalore   \n",
       "36                                 ASCO consulting                 New Delhi   \n",
       "37                                         NY INST                   Chennai   \n",
       "38  3D India Staffing Research &amp; Consulting...                   Aligarh   \n",
       "39                                     O.C. Tanner            Salt Lake City   \n",
       "40                                   Demand Matrix                      Pune   \n",
       "41                             MADHUSUDHAN SRIDHAR     Bengaluru / Bangalore   \n",
       "42                                  Suntech Global                    Mumbai   \n",
       "43                        Strategic Consulting Lab                    Indore   \n",
       "44                            Impel Labs Pvt. Ltd.     Bengaluru / Bangalore   \n",
       "45                                    MRP Advisers                    MYSORE   \n",
       "46                   Saras Solutions India Pvt Ltd  Hyderabad / Secunderabad   \n",
       "47                                     WildJasmine     Bengaluru / Bangalore   \n",
       "48                             LNT Private Limited                    Mumbai   \n",
       "49                                     Granular.ai                         -   \n",
       "\n",
       "                                                Skill  \n",
       "0   Classic ASP Developer, Internet Marketing Prof...  \n",
       "1   .Net, Java, Data Science, Linux Administration...  \n",
       "2   Data Science, Artificial Intelligence, Machine...  \n",
       "3   Mean Stack, javascript, angularjs, mongodb, We...  \n",
       "4   Hadoop, Spark, Digital Strategy, Data Architec...  \n",
       "5   Analytics, Business Intelligence, Business Ana...  \n",
       "6                                        Data Science  \n",
       "7   Machine Learning, algorithms, Go Getter, Compu...  \n",
       "8   Technical Training, Software Development, Pres...  \n",
       "9   Software Development, It Sales, Account Manage...  \n",
       "10  Social Media, digital media maketing, seo, smm...  \n",
       "11  Oracle Dba, Data Science, Data Warehousing, ET...  \n",
       "12  Qa, Ui/ux, Java Developer, Java Architect, C++...  \n",
       "13  Business Intelligence, Data Warehousing, Data ...  \n",
       "14  Office Administration, Hr Administration, tele...  \n",
       "15               Data Science, Python, Data Analytics  \n",
       "16     Big Data, Hadoop, Data Analytics, Data Science  \n",
       "17  React.js, Data Science, Java, Front End, Busin...  \n",
       "18  Qlikview, Qlik Sense, Microsoft Azure, Power B...  \n",
       "19  Telecalling, Client Interaction, Marketing, Re...  \n",
       "20                                       Data Science  \n",
       "21  Corporate Sales, Software Development, Softwar...  \n",
       "22  Data Analytics, Data Science, Machine Learning...  \n",
       "23  Data Science, Machine Learning, Python, R, Dee...  \n",
       "24  Big Data, Data Science, Artificial Intelligenc...  \n",
       "25  Java, Net, Angularjs, Hr, Infrastructure, Mana...  \n",
       "26  Data Science, Artificial Intelligence, Machine...  \n",
       "27  Software Architecture, Vp Engineering, Product...  \n",
       "28  Data Science, Hadoop, Rpas, Devops, Python, Aw...  \n",
       "29  Signal Processing, Machine Learning, Neural Ne...  \n",
       "30  Web Technologies, Project Management, Software...  \n",
       "31  Server Administartion, Verilog, Vhdl, Digital ...  \n",
       "32  Data Analytics, Managed Services, Team Leading...  \n",
       "33  Ethical Hacking, Security Operations Center, S...  \n",
       "34  Data Science, Machine Learning, Big Data Analy...  \n",
       "35  Data Science, Artificial Intelligence, analyti...  \n",
       "36  Machine Learning, Artificial Intelligence, Dat...  \n",
       "37  C, C++, Artificial Intelligence, Python, Php, ...  \n",
       "38  Relationship Management, Retail Sales, Private...  \n",
       "39                 Data Science, Software Engineering  \n",
       "40  Data Science, Big Data Analytics, Digital Mark...  \n",
       "41                  Data Science, Recruitment, Salary  \n",
       "42  B.Tech, Tableau, Statistics, R, Analytics, Tim...  \n",
       "43  Software Development, Business Intelligence, B...  \n",
       "44                   Data Science, Node.js, Angularjs  \n",
       "45  Data Science, Media Marketing, Resource Planni...  \n",
       "46  Data Analysis, Learning, Data Science, Compute...  \n",
       "47  Java, Hadoop, R, Machine Learning, Spark, Flum...  \n",
       "48  Software Development, Core Java, Unit Testing,...  \n",
       "49  Machine Learning, Data Science, Product Manage...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's first connect to webdriver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "# Opening target url page on automated chrome browser\n",
    "driver.get('https://www.naukri.com/data-science-recruiters')\n",
    "time.sleep(3)\n",
    "\n",
    "# Creating empty list\n",
    "name=[]\n",
    "desig=[]\n",
    "comp=[]\n",
    "loc=[]\n",
    "\n",
    "# Scrapping details\n",
    "recruiter=[i.text.split('\\n') for i in driver.find_elements(By.XPATH,\"//p[@class='highlightable']\")]\n",
    "for i in recruiter:\n",
    "    try:\n",
    "        name.append(i[0])\n",
    "    except:\n",
    "        name.append('-')\n",
    "    try:\n",
    "        desig.append(i[1])\n",
    "    except:\n",
    "        desig.append('-')\n",
    "    try:\n",
    "        comp.append(i[2])\n",
    "    except:\n",
    "        comp.append('-')\n",
    "    try:\n",
    "        loc.append(i[3])\n",
    "    except:\n",
    "        loc.append('-')\n",
    "skill=[i.text for i in driver.find_elements(By.XPATH,\"//div[@class='hireSec highlightable']\")]    \n",
    "\n",
    "# Saving the lists as dataframe\n",
    "df=pd.DataFrame({'Name':name,'Designation':desig,'Company':comp,'Location':loc,'Skill':skill})\n",
    "print('Data Science recruiters from Naukri')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b9f2c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a234e",
   "metadata": {},
   "source": [
    "# Q8.Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey- compare/\n",
    "You have to find the following details:\n",
    "\n",
    "A) Book name\n",
    "\n",
    "B) Author name\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2ce36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's first connect to webdriver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Opening target url page on automated chrome browser\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f16e9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest selling Novels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the empty list\n",
    "name=[]\n",
    "author=[]\n",
    "volume=[]\n",
    "publisher=[]\n",
    "genre=[]\n",
    "\n",
    "# Scraping for name\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[2]\"):\n",
    "    name.append(i.text)\n",
    "\n",
    "# Scraping for author\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[3]\"):\n",
    "    author.append(i.text)\n",
    "\n",
    "# Scraping for volume\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[4]\"):\n",
    "    volume.append(i.text)\n",
    "\n",
    "# Scraping for publisher\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[5]\"):\n",
    "    publisher.append(i.text)\n",
    "\n",
    "# Scraping for genre\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[6]\"):\n",
    "    genre.append(i.text)\n",
    "    \n",
    "# Creating the Dataframe\n",
    "novels={'Book Name':name,'Author Name':author,'Volumes sold':volume,'Publisher':publisher,'Genre':genre}\n",
    "df=pd.DataFrame(data=novels)\n",
    "print('Highest selling Novels')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09b304f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62295489",
   "metadata": {},
   "source": [
    "# Q9. Scrape the details most watched tv series of all time from imdb.com.            \n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "146ba2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first connect to webdriver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "# Opening target url page on automated chrome browser\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e05c28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most watched TV Series of all time from IMDB.COM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,062,691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,156,033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>972,877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>290,032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>249,417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>49,708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>60,773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>195,617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>238,382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0    57 min     9.2  2,062,691  \n",
       "1    51 min     8.7  1,156,033  \n",
       "2    44 min     8.1    972,877  \n",
       "3    60 min     7.5    290,032  \n",
       "4    43 min     7.6    249,417  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     49,708  \n",
       "96   50 min     7.8     60,773  \n",
       "97   42 min     8.1    195,617  \n",
       "98   45 min     7.1     41,166  \n",
       "99  572 min     8.6    238,382  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the empty list\n",
    "name=[]\n",
    "year=[]\n",
    "genre=[]\n",
    "runtime=[]\n",
    "rating=[]\n",
    "votes=[]\n",
    "\n",
    "# Scraping name of the series\n",
    "for i in driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\"):\n",
    "    name.append(i.text)\n",
    "# Scraping year    \n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    year.append(i.text)\n",
    "# Scraping genre\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='genre']\"):\n",
    "    genre.append(i.text)\n",
    "# Scrapping runtime    \n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='runtime']\"):\n",
    "    runtime.append(i.text)\n",
    "# Scraping rating\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='main']/div/div[3]/div[3]/div/div[2]/div[1]/div[1]/span[2]\"):\n",
    "    rating.append(i.text)\n",
    "# Scraping votes\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@name='nv']\"):\n",
    "    votes.append(i.text)\n",
    "\n",
    "# Creating the dataframe\n",
    "imdb={'Name':name,'Year Span':year,'Genre':genre,'Run time':runtime,'Ratings':rating,'Votes':votes}\n",
    "df=pd.DataFrame(data=imdb)\n",
    "print ('Most watched TV Series of all time from IMDB.COM')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9207e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeec182",
   "metadata": {},
   "source": [
    "# Q10. Details of Datasets from UCI machine learning repositories.                  \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "\n",
    "A) Dataset name\n",
    "\n",
    "B) Data type\n",
    "\n",
    "C) Task\n",
    "\n",
    "D) Attribute type\n",
    "\n",
    "E) No of instances\n",
    "\n",
    "F) No of attribute\n",
    "\n",
    "G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "605a1bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first connect to webdriver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "# Opening target url page on automated chrome browser\n",
    "driver.get('https://archive.ics.uci.edu/')\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70187b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of datasets from UCI Machine Learning repositories\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attribue</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data Type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute Type No of Instances No of Attribue   Year  \n",
       "0    Categorical, Integer, Real            4177              8   1995   \n",
       "1          Categorical, Integer           48842             14   1996   \n",
       "2    Categorical, Integer, Real             798             38          \n",
       "3                   Categorical           37711            294   1998   \n",
       "4    Categorical, Integer, Real             452            279   1998   \n",
       "..                           ...             ...            ...    ...  \n",
       "617               Integer, Real           75840            525   2020   \n",
       "618               Integer, Real             400             50   2020   \n",
       "619                                        1014              7   2020   \n",
       "620                        Real           10129             16   2021   \n",
       "621                        Real            4000              2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clicking on view all dataset\n",
    "dataset=driver.find_element(By.XPATH,\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a\")\n",
    "driver.get(dataset.get_attribute('href'))\n",
    "\n",
    "# Creating the empty list\n",
    "name=[]\n",
    "datatype=[]\n",
    "task=[]\n",
    "attribute=[]\n",
    "instances=[]\n",
    "no_attribute=[]\n",
    "year=[]\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Scraping dataset name\n",
    "for i in driver.find_elements(By.XPATH,\"//tr['@bgcolor=#003366']/td/table/tbody/tr/td[2]/p/b/a\"):\n",
    "    name.append(i.text)\n",
    "    \n",
    "# Scraping datatype\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[2]/p\"):\n",
    "    datatype.append(i.text)\n",
    "datatype=datatype[1:]\n",
    "\n",
    "# Scraping task\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[3]/p\"):\n",
    "    task.append(i.text)\n",
    "task=task[1:]\n",
    "\n",
    "# Scraping attribute\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[4]/p\"):\n",
    "    attribute.append(i.text)\n",
    "attribute=attribute[1:]\n",
    "\n",
    "# Scraping instances\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[5]/p\"):\n",
    "    instances.append(i.text)\n",
    "instances=instances[1:]\n",
    "\n",
    "# Scraping attributes\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[6]/p\"):\n",
    "    no_attribute.append(i.text)\n",
    "no_attribute=no_attribute[1:]\n",
    "\n",
    "# Scraping year\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[7]/p\"):\n",
    "    year.append(i.text)\n",
    "year=year[1:]\n",
    "\n",
    "# Creating the dataset\n",
    "uci={'Dataset Name':name,'Data Type':datatype,'Task':task,'Attribute Type':attribute,\n",
    "    'No of Instances':instances,'No of Attribue':no_attribute,'Year':year}\n",
    "df=pd.DataFrame(data=uci)\n",
    "print('Details of datasets from UCI Machine Learning repositories')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32243a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
